{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuIup1gThXD3mRY6s+lGFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymkge/GenerativeAI_practice/blob/main/%E5%8B%95%E7%94%BB%E3%81%AE%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E3%81%A8%E3%82%B3%E3%83%B3%E3%83%97%E3%83%A9%E3%83%81%E3%82%A7%E3%83%83%E3%82%AF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事前準備"
      ],
      "metadata": {
        "id": "RzF8I7d6hkHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインストール\n",
        "!pip install -U yt-dlp\n",
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW6ueeF_hiL6",
        "outputId": "fe3f6aa7-c204-4840-ee19-a1be052c6e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.10.7)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.8.30)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.21.0)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.2.3)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.10)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## youtubeの動画情報を取得し、whisperで文字起こしを行う"
      ],
      "metadata": {
        "id": "rsb6o_KxjYx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YouTube動画のURLを指定\n",
        "video_url = \"https://www.youtube.com/watch?v=STKeyxG3gWs&t=13s\"\n",
        "\n",
        "# yt-dlpを使用して音声をダウンロード\n",
        "import yt_dlp\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'extractaudio': True,  # 音声のみを抽出\n",
        "    'audioformat': 'mp3',  # 音声の形式\n",
        "    'outtmpl': 'downloaded_audio.%(ext)s',  # 保存するファイル名\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([video_url])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4TSqVZlhs4h",
        "outputId": "7f58cfda-db07-4425-a9dc-ef2decf79cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=STKeyxG3gWs&t=13s\n",
            "[youtube] STKeyxG3gWs: Downloading webpage\n",
            "[youtube] STKeyxG3gWs: Downloading ios player API JSON\n",
            "[youtube] STKeyxG3gWs: Downloading mweb player API JSON\n",
            "[youtube] STKeyxG3gWs: Downloading m3u8 information\n",
            "[info] STKeyxG3gWs: Downloading 1 format(s): 251\n",
            "[download] downloaded_audio.webm has already been downloaded\n",
            "[download] 100% of    5.99MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Whisperモデルのインポートとロード\n",
        "import whisper\n",
        "\n",
        "# Whisperモデルのロード\n",
        "# model = whisper.load_model(\"large\")\n",
        "model = whisper.load_model(\"tiny\") ## モデルが重過ぎてクラッシュする場合はこちらを利用\n",
        "\n",
        "# 音声ファイルの文字起こし\n",
        "result = model.transcribe(\"downloaded_audio.webm\")\n",
        "\n",
        "# 文字起こし結果を表示\n",
        "transcribed_text = result[\"text\"]\n",
        "print(transcribed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgMsr6zInrl9",
        "outputId": "16da8adc-23d7-4449-ae1b-ddb36b0bf65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 59.4MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "お金のニュース 直近やりすぎ注意日本インフレ続きます10月も1日のお金のニュース 石橋章新派なのはぶっかだかですかで触れですか石橋章を利上げに関して手の開害しをしたようっていうニュースです 十月ついたちに石橋内隠が単調しましたね当下にとってきいなるのは石橋章の経済センス 雑霊は石橋の経済センスがいいと株化が上がる石橋の経済センスが悪いと株化が下がる石橋のカジトリは当下の最具に大力とに直撃しますからね さて石橋章は総理集に前はこんな感じのことを言ってみましたイングレ進んでてよくないですな 金利を上げて利害して経済さましましょうかこういうことで言ってたですね 日本の政策金利は現在0.25%これをもっとあげちゃっていいんじゃないってことですね ところがどこい総理集人号見事に手の開害しをしました 水壊り上げの環境にない金利あげないでよろしいってことです 僕としてはこのメッセージには多いに3セージです総理の周りに優秀なブレインがいたようで何よりです でインクレでくれ改めて整理しましょう インクレというのはものやサービスの価格が経済的に上昇する状態 一向100円だったお逃げ切りが来年には1.110円になるそんなイメージです ものとの比較で言えば通過の価値が下がっているってことですね 一方でふれはものやサービスの価格が経済的にギャラクする状態です 一向100円だったお逃げ切りが来年には1.90円になるっていうイメージですね こちらは通過の価値が上がっているっていう状態です 下手ここでみなさに質問ですインフレートでふれどっちがいいですか どうでしょう皆さん意外と新権に考えたことないんじゃないですか これについてどう考えるかは今後の資産形成選択にめちゃくちゃ大きく影響します ぜひ自分なりに新権に考えて見てほしいです 実はこういう議論にはいいまるまるとか悪いまるまるという話がつきものです 最近だといいエンダか悪いエンダかいいインフレ悪いインフレみたいな言葉を皆さんも 右期したんじゃないですかねこれと同じ話でちょっと昔の日本でいいでふれロンソーってのがあったんですね1990年代に起きたロンソーです 当時日本ではぶっかのギャラクが続いていましたそれに対していいでふれなら絵案っていう視聴があったんですね ところが長いでふれを通じて日本がどうなったかは皆さんが一番よく知ってるでしょう ぶっかがあがらない企業の売り上げが伸びないだからチンギもあがらないチンギがあがらないから 自由も伸びないものが売れないこの事故くのスパイラルで経済の成長がストップするわけです 今やいいでふれなんてものは存在しないっていうのが通説になっています ぶっか水準が下がり続けるのは常にこのましくないってこといいでふれと悪いでふれの首つなんてない でふれとにかくさけるべしとそういうのが通説になってますね一方でインフレにはいいインフレと悪いインフレがあります いいインフレというのはいるやかにぶっかがあがって企業の売り上げが伸びて皆さんのチンギもいるやかにあがる そしてみんなの幸せが売ろうってみんながさらにものをかうよりなって自由が増えてまた許やかにぶっかががってっていう感じで 経済全体が成長していくものですね一方悪いインフレというのはいわゆるハイパイインフレみたいなやつです 戦争が起きての上や工場が壊されてパンが一庫100万円になりましたとか政府がお金をすり過ぎて通過の信用が失われてお金がごみになりましたとか そういやつですね質問に戻りましょう結局インフレとでふれどっちがいいですか この質問に対する答えは実のところ一つしかありませんと僕は思っています 結論インフレのみかもんって言うねずにするとこういう感じでふれはダメ ブックが下がると企業の売り上げが下がる生産は縮小されるしこういうものも作業される まさに不計期ですでふれの世界ではシャッキンはフリーになります 通過の価値が上がっていくってことは裏を返せばシャッキンのもみもどんどん増えていくということお金の価値が上がるというのはお金をかすぐのが大変になっているってことといこうるですブックがギラック施設けたら会社は売り上げを伸ばすの大変でしょう ででふれが進めば進むほうどシャッキン編載の2話どんどんもくなります 多くの会社は高くの借り入れを行って事業計用していますでふれになるとサイムのおもみに帯られなくなって果たんする企業が出てきます そして連損さに繋がっていくわけですねそして必要者がますます増えていくでふれにいいでくれなんてもな存在しない だから今世界中の国がインフレを起こそうとしているわけですね悪いインフレ 配配フレをさけるよう気をつけながらいいインフレを起こそうとやっきになっています このことが分かると日本で今何が話題になっているのか これからどうなるのかなぜアメリカでこんなにもブックか 雇用とおけ金利が話題になっているのか理解しやすくなると思いますよ経済性作はいいインフレのため これをしっかり当たまに戦い聞こんでおきましょうまとめいきましょう 一日視聴が手のひらがいしをしました 周人前は緊急上げちゃっておっけいですってとのに周人後は緊急上げる環境にないですって ですね日本はまだまだいいインフレになってるとはいいがたいです神人の伸び全然足りてませんしねこんな状況で緊急上げて経済さましてどないすんねんっていうのが僕の考えブックかだかを心配するよりもデフレに逆戻りすることを心配した方がいい 多くのマーケット関係者もそうもっているんじゃないですかね経済の目指す方向性大きくはいいインフレしかありません このずの通りですね今後は過去数十年と違ってブックかが経済的に上がって数かの勝ちは許やかに下がっていく そういう時代になっていくんじゃないですかねこういう世界では直近は必ずしも正義ではありません 他コーナーの500ミリリットルのベットボトル今や一本1810円ですからねブックかが上がり続ける世界では直近では公倍力を意味できませんか部屋太さんに通ししていないと公倍力は下がり続ける一方です 経済はどこへ向かっているのか報告性を見やえまらないようにクレグレーも気をつけていきましょう 以上ですご視聴ありがとうございました\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8kw1Kangq0H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 自然言語処理によるテキストの適正化"
      ],
      "metadata": {
        "id": "OTE0tUR6g35r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatGPT APIを使用してテキストを修正\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"以下のテキストを自然な表現に修正してください: {transcribed_text}\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "optimized_text = response['choices'][0]['message']['content']\n"
      ],
      "metadata": {
        "id": "Ws0alrfog0yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. コンプライアンスチェックの実施"
      ],
      "metadata": {
        "id": "dTLz0BJLg_Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# コンプライアンスチェック用のキーワードリスト\n",
        "keywords = [\"暴力\", \"差別\", \"攻撃\", \"侮辱\"]\n",
        "\n",
        "# テキストのスキャン\n",
        "def compliance_check(text, keywords):\n",
        "    flagged_sentences = []\n",
        "    for sentence in text.split('.'):\n",
        "        if any(keyword in sentence for keyword in keywords):\n",
        "            flagged_sentences.append(sentence.strip())\n",
        "    return flagged_sentences\n",
        "\n",
        "flagged_expressions = compliance_check(optimized_text, keywords)\n"
      ],
      "metadata": {
        "id": "Yq92FLNPg_j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 修正提案の生成"
      ],
      "metadata": {
        "id": "_h2kKpVqhD6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 修正提案の生成\n",
        "corrections = {}\n",
        "for expression in flagged_expressions:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"以下の表現を適切な表現に修正してください: {expression}\"}\n",
        "        ]\n",
        "    )\n",
        "    corrections[expression] = response['choices'][0]['message']['content']\n"
      ],
      "metadata": {
        "id": "5UmxF-mMhEWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 修正後のテキストの確認と表示"
      ],
      "metadata": {
        "id": "W7wRswTkhH2g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uwvr_RQwD1SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ENz_qfxuD1U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインストール\n",
        "!pip install better-profanity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9i5blAgGBn1",
        "outputId": "074bc43f-e888-48ad-fc66-d505a05c6303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting better-profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: better-profanity\n",
            "Successfully installed better-profanity-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from better_profanity import profanity\n",
        "import re\n",
        "\n",
        "# 除外したい暴力的なフレーズのリスト\n",
        "violent_phrases = [\n",
        "    \"殴る\", \"暴力\", \"攻撃\", \"傷つける\", \"戦争\", \"虐待\"\n",
        "]\n",
        "\n",
        "# profanityライブラリの初期化\n",
        "profanity.load_censor_words()\n",
        "\n",
        "def censor_violent_phrases(text):\n",
        "    # 暴力的なフレーズを「〇」に置き換える\n",
        "    for phrase in violent_phrases:\n",
        "        text = re.sub(phrase, \"〇\", text)\n",
        "    return text\n",
        "\n",
        "def filter_transcripts(transcripts):\n",
        "    filtered_transcripts = []\n",
        "    for transcript in transcripts:\n",
        "        # 暴力的なフレーズを置き換えたテキストを取得\n",
        "        censored_text = censor_violent_phrases(transcript)\n",
        "        filtered_transcripts.append(censored_text)\n",
        "    return filtered_transcripts\n",
        "\n",
        "# サンプルの文字起こしデータ\n",
        "transcripts = [\n",
        "    \"今日は楽しい日です。\",\n",
        "    \"私は彼を殴るつもりです。\",\n",
        "    \"暴力では解決になりません。\",\n",
        "    \"このプロジェクトは素晴らしいです。\"\n",
        "    \"弱者への虐待をしてはいけません。\"\n",
        "]\n",
        "\n",
        "# フィルタリングを実行\n",
        "filtered_transcripts = filter_transcripts(transcripts)\n",
        "\n",
        "# 結果を表示\n",
        "print(\"フィルタリング後の文字起こし:\")\n",
        "for text in filtered_transcripts:\n",
        "    print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTVgYa0cHrYf",
        "outputId": "8af53c04-cbbe-4dda-ab18-4f828c4ec9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "フィルタリング後の文字起こし:\n",
            "今日は楽しい日です。\n",
            "私は彼を〇つもりです。\n",
            "〇では解決になりません。\n",
            "このプロジェクトは素晴らしいです。弱者への〇をしてはいけません。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6xaDQUwImcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9btBKvh5J34k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}